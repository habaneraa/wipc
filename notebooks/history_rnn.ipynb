{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - 加载数据集并转换为 Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from src.data.load import load_dataset\n",
    "from src.data.utils import load_compressed, save_compressed\n",
    "from src.data.post_sequence import build_user_historical_sequences, PostSequenceDataset\n",
    "\n",
    "raw_data = load_dataset()\n",
    "def load_histories(dataset_path='./data/histories.pkl.gz'):\n",
    "    if Path(dataset_path).exists():\n",
    "        return load_compressed(dataset_path)\n",
    "    else:\n",
    "        obj = build_user_historical_sequences(raw_data['all_train'])\n",
    "        save_compressed(obj, dataset_path)\n",
    "        return obj\n",
    "user_histories = load_histories()\n",
    "training_dataset = PostSequenceDataset(user_histories)\n",
    "len(training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - 创建模型和相关参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.recurrent import RNN\n",
    "from src.trainer import Trainer, TrainingArguments\n",
    "\n",
    "feature_size = training_dataset[0][0].shape[-1]\n",
    "seq_reg_model = RNN(feature_size, hidden_size=16)\n",
    "trainer = Trainer(\n",
    "    training_dataset, None, None,\n",
    "    seq_reg_model,\n",
    "    TrainingArguments(\n",
    "        epochs=20,\n",
    "        batch_size=64,\n",
    "        learning_rate=0.01,\n",
    "        lr_gamma=0.9\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - 训练循环网络和预测器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - 利用循环网络提取用户特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "user_feature: dict[str, torch.FloatTensor] = {}\n",
    "seq_reg_model.to('cpu')\n",
    "seq_reg_model.eval()\n",
    "for user_sample in tqdm(user_histories):\n",
    "    # 这里暂时不知道怎么并行 大概要等 1 分钟\n",
    "    x = user_sample['x_tensor'].unsqueeze(1)\n",
    "    x_len = user_sample['x_len']\n",
    "    y = user_sample['y'].unsqueeze(1)\n",
    "    model_outputs = seq_reg_model(x, x_len, y)\n",
    "    user_feature[user_sample['uid']] = model_outputs.last_hidden_state.view(-1).clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - 在验证集和测试集上进行回归预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.features import extract_features\n",
    "from src.data.process import exp_targets, extract_targets\n",
    "\n",
    "valid_set_feature = extract_features(raw_data['valid'], None)\n",
    "test_set_feature = extract_features(raw_data['test'], None)\n",
    "valid_set_targets = extract_targets(raw_data['valid'], 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def run_predict(dataset) -> np.ndarray:\n",
    "    all_pred = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        if row['uid'] in user_feature:\n",
    "            hidden = user_feature[row['uid']].unsqueeze(0)\n",
    "        else:\n",
    "            hidden = torch.zeros((1, seq_reg_model.hidden_size))\n",
    "        x_in = torch.Tensor( row['feature_content'].tolist()+row['feature_datetime'].tolist() ).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            model_out = seq_reg_model(x=x_in, last_hidden=hidden)\n",
    "        all_pred.append(model_out.logits.numpy())\n",
    "\n",
    "    return exp_targets( np.concatenate(all_pred, axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metric import compute_metrics\n",
    "\n",
    "predicts = run_predict(raw_data['valid'])\n",
    "compute_metrics(predicts, valid_set_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_predicts = run_predict(raw_data['test'])\n",
    "results = []\n",
    "for i in range(len(raw_data['test'])):\n",
    "    results.append(\n",
    "        \"{}\\t{}\\t{},{},{}\\n\".format(\n",
    "            raw_data['test'].loc[i, 'uid'],\n",
    "            raw_data['test'].loc[i, 'mid'],\n",
    "            test_set_predicts[i, 1],\n",
    "            test_set_predicts[i, 2],\n",
    "            test_set_predicts[i, 0]\n",
    "        )\n",
    "    )\n",
    "with open(\"submission.txt\", 'w') as f:\n",
    "    f.writelines(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weibo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

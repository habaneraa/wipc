{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TabularPredictor(problem_type='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044681\n",
      "184937\n",
      "1229618\n",
      "178297\n",
      "37960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting User Histories: 100%|██████████| 1044681/1044681 [00:26<00:00, 39225.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dim: 34\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.data.load import load_dataset\n",
    "from src.data.process import extract_targets\n",
    "from src.data.features import extract_user_feature, extract_features\n",
    "\n",
    "data = load_dataset()\n",
    "# for k, v in data.items():\n",
    "#     print(len(v))\n",
    "\n",
    "user_features = extract_user_feature(data['train'], data['all_uid'])\n",
    "features_train = extract_features(data['train'], user_features)\n",
    "features_valid = extract_features(data['valid'], user_features)\n",
    "features_test = extract_features(data['test'], user_features)\n",
    "print('feature dim:', features_train.shape[1])\n",
    "targets_train = extract_targets(data['train'], 'log')\n",
    "targets_valid = extract_targets(data['valid'], 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240322_083347\\\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (1044681 samples, 288.33 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240322_083347\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Train Data Rows:    1044681\n",
      "Train Data Columns: 34\n",
      "Label Column: target\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (9.381937980651855, 0.0, 0.3336600065231323, 0.7252900004386902)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11794.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 284.15 MB (2.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 15 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 34 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 19 | ['15', '16', '17', '18', '19', ...]\n",
      "\t\t('int', ['bool']) : 15 | ['0', '1', '2', '3', '4', ...]\n",
      "\t3.3s = Fit runtime\n",
      "\t34 features in original data used to generate 34 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 174.46 MB (1.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.9s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 1034234, Val Rows: 10447\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.4992\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.01s\t = Training   runtime\n",
      "\t6.61s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.5248\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t6.72s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.441483\n",
      "[2000]\tvalid_set's rmse: 0.438858\n",
      "[3000]\tvalid_set's rmse: 0.437922\n",
      "[4000]\tvalid_set's rmse: 0.436964\n",
      "[5000]\tvalid_set's rmse: 0.436704\n",
      "[6000]\tvalid_set's rmse: 0.436483\n",
      "[7000]\tvalid_set's rmse: 0.436125\n",
      "[8000]\tvalid_set's rmse: 0.436163\n",
      "[9000]\tvalid_set's rmse: 0.435978\n",
      "[10000]\tvalid_set's rmse: 0.435829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4358\t = Validation score   (-root_mean_squared_error)\n",
      "\t126.44s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.441742\n",
      "[2000]\tvalid_set's rmse: 0.438956\n",
      "[3000]\tvalid_set's rmse: 0.438147\n",
      "[4000]\tvalid_set's rmse: 0.437892\n",
      "[5000]\tvalid_set's rmse: 0.438554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4378\t = Validation score   (-root_mean_squared_error)\n",
      "\t88.35s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.4427\t = Validation score   (-root_mean_squared_error)\n",
      "\t620.07s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.4394\t = Validation score   (-root_mean_squared_error)\n",
      "\t565.53s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.4354\t = Validation score   (-root_mean_squared_error)\n",
      "\t536.59s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t-0.5613\t = Validation score   (-root_mean_squared_error)\n",
      "\t480.86s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.4424\t = Validation score   (-root_mean_squared_error)\n",
      "\t38.83s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.4741\t = Validation score   (-root_mean_squared_error)\n",
      "\t606.59s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.437071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4369\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.17s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.4335\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3118.19s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240322_083347\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240322_092545\\\"\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (1044681 samples, 288.33 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240322_092545\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Train Data Rows:    1044681\n",
      "Train Data Columns: 34\n",
      "Label Column: target\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (10.641871452331543, 0.0, 0.29732999205589294, 0.8094800114631653)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12821.73 MB\n",
      "\tTrain Data (Original)  Memory Usage: 284.15 MB (2.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 15 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 34 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 19 | ['15', '16', '17', '18', '19', ...]\n",
      "\t\t('int', ['bool']) : 15 | ['0', '1', '2', '3', '4', ...]\n",
      "\t3.6s = Fit runtime\n",
      "\t34 features in original data used to generate 34 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 174.46 MB (1.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.68s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 1034234, Val Rows: 10447\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.56\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t8.3s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.5928\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t8.09s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.496182\n",
      "[2000]\tvalid_set's rmse: 0.492677\n",
      "[3000]\tvalid_set's rmse: 0.491014\n",
      "[4000]\tvalid_set's rmse: 0.490714\n",
      "[5000]\tvalid_set's rmse: 0.490158\n",
      "[6000]\tvalid_set's rmse: 0.489985\n",
      "[7000]\tvalid_set's rmse: 0.489625\n",
      "[8000]\tvalid_set's rmse: 0.489487\n",
      "[9000]\tvalid_set's rmse: 0.489673\n",
      "[10000]\tvalid_set's rmse: 0.489952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4894\t = Validation score   (-root_mean_squared_error)\n",
      "\t113.06s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.4946\n",
      "[2000]\tvalid_set's rmse: 0.491111\n",
      "[3000]\tvalid_set's rmse: 0.490139\n",
      "[4000]\tvalid_set's rmse: 0.490886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4899\t = Validation score   (-root_mean_squared_error)\n",
      "\t41.81s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.5008\t = Validation score   (-root_mean_squared_error)\n",
      "\t680.85s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.4918\t = Validation score   (-root_mean_squared_error)\n",
      "\t391.14s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.4931\t = Validation score   (-root_mean_squared_error)\n",
      "\t706.99s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t-0.6268\t = Validation score   (-root_mean_squared_error)\n",
      "\t312.11s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.4947\t = Validation score   (-root_mean_squared_error)\n",
      "\t56.08s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.5379\t = Validation score   (-root_mean_squared_error)\n",
      "\t1121.21s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.488399\n",
      "[2000]\tvalid_set's rmse: 0.485987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4859\t = Validation score   (-root_mean_squared_error)\n",
      "\t75.73s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.4853\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3525.11s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240322_092545\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240322_102430\\\"\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (1044681 samples, 288.33 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240322_102430\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Train Data Rows:    1044681\n",
      "Train Data Columns: 34\n",
      "Label Column: target\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (8.91838264465332, 0.0, 0.2870999872684479, 0.663070023059845)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12626.38 MB\n",
      "\tTrain Data (Original)  Memory Usage: 284.15 MB (2.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 15 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 34 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 19 | ['15', '16', '17', '18', '19', ...]\n",
      "\t\t('int', ['bool']) : 15 | ['0', '1', '2', '3', '4', ...]\n",
      "\t3.8s = Fit runtime\n",
      "\t34 features in original data used to generate 34 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 174.46 MB (1.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.81s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 1034234, Val Rows: 10447\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.5433\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t8.32s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.5769\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t8.35s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.477076\n",
      "[2000]\tvalid_set's rmse: 0.475923\n",
      "[3000]\tvalid_set's rmse: 0.475289\n",
      "[4000]\tvalid_set's rmse: 0.474907\n",
      "[5000]\tvalid_set's rmse: 0.474494\n",
      "[6000]\tvalid_set's rmse: 0.474802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4745\t = Validation score   (-root_mean_squared_error)\n",
      "\t122.14s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.476799\n",
      "[2000]\tvalid_set's rmse: 0.475622\n",
      "[3000]\tvalid_set's rmse: 0.475685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4755\t = Validation score   (-root_mean_squared_error)\n",
      "\t61.45s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.4812\t = Validation score   (-root_mean_squared_error)\n",
      "\t858.74s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.4765\t = Validation score   (-root_mean_squared_error)\n",
      "\t160.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.4774\t = Validation score   (-root_mean_squared_error)\n",
      "\t678.45s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 3: early stopping\n",
      "\t-0.505\t = Validation score   (-root_mean_squared_error)\n",
      "\t850.24s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.4775\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.49s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.5166\t = Validation score   (-root_mean_squared_error)\n",
      "\t3258.15s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.475\n",
      "[2000]\tvalid_set's rmse: 0.474558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4742\t = Validation score   (-root_mean_squared_error)\n",
      "\t74.72s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.473\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6125.09s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240322_102430\\\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_dataframe(features: np.ndarray, targets: np.ndarray, target_id: int) -> pd.DataFrame:\n",
    "    df = pd.DataFrame(features)\n",
    "    df['target'] = targets[:,target_id]\n",
    "    return df\n",
    "\n",
    "df_train = [\n",
    "    create_dataframe(features_train, targets_train, 0),\n",
    "    create_dataframe(features_train, targets_train, 1),\n",
    "    create_dataframe(features_train, targets_train, 2),\n",
    "]\n",
    "\n",
    "predictors = [\n",
    "    TabularPredictor(problem_type='regression' , label='target').fit(df) for df in df_train\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = [\n",
    "    create_dataframe(features_valid, targets_valid, 0),\n",
    "    create_dataframe(features_valid, targets_valid, 1),\n",
    "    create_dataframe(features_valid, targets_valid, 2),\n",
    "]\n",
    "\n",
    "valid_set_predictions = [\n",
    "    predictor.predict(df_valid[i].drop(columns=['target'])) for i, predictor in enumerate(predictors)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184937, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be (N, 3)\n",
    "valid_set_predictions = np.stack(valid_set_predictions, axis=1)\n",
    "valid_set_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.35391315817832947}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metric import compute_metrics\n",
    "\n",
    "def exp_interactions(x: np.ndarray) -> np.ndarray:\n",
    "    return np.rint(np.exp(x) - 1).astype(int)\n",
    "compute_metrics(exp_interactions(valid_set_predictions), targets_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_set_predictions = [\n",
    "    predictor.predict(pd.DataFrame(features_test)) for i, predictor in enumerate(predictors)\n",
    "]\n",
    "test_set_predictions = np.stack(test_set_predictions, axis=1)\n",
    "\n",
    "test_set_predicts = exp_interactions(test_set_predictions)\n",
    "results = []\n",
    "for i in range(len(data['test'])):\n",
    "    results.append(\n",
    "        \"{}\\t{}\\t{},{},{}\\n\".format(\n",
    "            data['test'].loc[i, 'uid'],\n",
    "            data['test'].loc[i, 'mid'],\n",
    "            test_set_predicts[i, 1],\n",
    "            test_set_predicts[i, 2],\n",
    "            test_set_predicts[i, 0]\n",
    "        )\n",
    "    )\n",
    "with open(\"submission.txt\", 'w') as f:\n",
    "    f.writelines(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
